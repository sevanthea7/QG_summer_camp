{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "建造服务端"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76b6fb614bdd264a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import socket\n",
    "server = socket.socket()\n",
    "\n",
    "server.bind( ( \"0.0.0.0\", 8800 ) )\n",
    "\n",
    "server.listen( 5 )\n",
    "\n",
    "while True:\n",
    "    conn, addr = server.accept()\n",
    "   \n",
    "    data = conn.recv( 1024 )\n",
    "    print( data )\n",
    "    \n",
    "    response = \"HTTP/1.1 200 OK\\r\\nContent-Type: text/html;charset=utf-8;\\r\\n\\r\\n<h1 style='color:black'>12345<h1>\"\n",
    "    \n",
    "    # 5. 发送数据\n",
    "    conn.send( response.encode() )\n",
    "    print( '已响应' )\n",
    "    \n",
    "server.close()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a9696f758bab6d0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "建造客户端"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4d8387fbf05e775"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "client = socket.socket()\n",
    "\n",
    "client.connect( ( 'www.baidu.com', 80 ) )\n",
    "\n",
    "data = b\"GET / HTTP/1.1\\r\\nHost: www.baidu.com\\r\\n\\r\\n\"\n",
    "\n",
    "client.send( data )\n",
    "res = b\"\"\n",
    "\n",
    "temp = client.recv( 1024 )\n",
    "while temp:\n",
    "    print( \"*\" * 50 )\n",
    "    res += temp\n",
    "    temp = client.recv( 1024 )\n",
    "    print( temp.decode() )\n",
    "    \n",
    "client.close()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc0291947ec6011e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "img = \"\"\n",
    "\n",
    "client = socket.socket()\n",
    "client.connect( ( '', 80))\n",
    "data = \"GET  HTTP/1.1\\r\\nHost:\\r\\n\\r\\n\"\n",
    "\n",
    "client.send( data.encode() )\n",
    "\n",
    "first_data = client.recv( 1024 )\n",
    "print( 'first_data: ', first_data )\n",
    "\n",
    "length = int( re.findall( b\"Content-Length: (.*?)\\r\\n\", first_data )[0]  )\n",
    "print( length )             # 内容长度\n",
    "\n",
    "image_data = re.findall( b\"From Inner Cluster \\r\\b\\r\\n(.*?)\", first_data, re.S )\n",
    "if image_data:\n",
    "    image_data = image_data[0]\n",
    "else:\n",
    "    image_data = b\"\"\n",
    "    \n",
    "while True:\n",
    "    temp = client.recv( 1024 )\n",
    "    image_data += temp\n",
    "    if len( image_data ) >= length:\n",
    "        break\n",
    "\n",
    "\n",
    "client.close()\n",
    "\n",
    "with open( \"123.jpg\", \"wb\" ) as file:\n",
    "    file.write( image_data )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53e408df0396ba3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "img_url = \"https://img1.baidu.com/it/u=3644696693,2035781770&fm=253&fmt=auto&app=120&f=JPEG?w=607&h=405\"\n",
    "\n",
    "# 发送HTTP GET请求\n",
    "response = requests.get(img_url)\n",
    "\n",
    "# 检查请求是否成功\n",
    "if response.status_code == 200:\n",
    "    # 保存图像数据到文件\n",
    "    with open(\"..\\data\\爬虫_耗子.jpg\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Image downloaded\")\n",
    "else:\n",
    "    print(\"Failed. Status code:\", response.status_code)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f12c360cef1263db",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import parsel\n",
    "\n",
    "url = 'https://www.tukuppt.com/yinxiaomuban/qichemingdi/__zonghe_0_0_0_0_0_0_1.html'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36',\n",
    "}\n",
    "response = requests.get( url = url, headers = headers )\n",
    "selector = parsel.Selector( response.text )\n",
    "print( response.status_code )\n",
    "\n",
    "urls = selector.css('#audio850995 source::attr(src)').getall()\n",
    "titles = selector.css('.b-box .info .title::text').getall()\n",
    "print( urls )\n",
    "\n",
    "data = zip(urls, titles)\n",
    "\n",
    "\n",
    "    \n",
    "def download_mp3( url, title, j ):\n",
    "    response = requests.get( url = url, headers = headers )\n",
    "    path = '..\\mp3\\car_sound' + j + '.mp3'\n",
    "    print( f'Downloading MP3 file' + title )\n",
    "    with open( path, 'wb' ) as file:\n",
    "        file.write( response.content )\n",
    "    \n",
    "\n",
    "j = 37\n",
    "for i in data:\n",
    "    mp3_url = 'https:' + i[0]\n",
    "    print( mp3_url )\n",
    "    title = i[1]\n",
    "    download_mp3( mp3_url, title, j )\n",
    "    j += 1\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e70b5010112feebb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36',\n",
    "    }\n",
    "response = requests.get('https://stock.zhipianbang.com/sound/search.html?keyword=%E4%BA%A4%E8%B0%88', headers = headers )\n",
    "content = response.text\n",
    "soup = BeautifulSoup( content, 'html.parser' )\n",
    "all_h2 = soup.findAll( 'h2', class_='over_text1 font16' )\n",
    "all_links = soup.findAll('a')\n",
    "link_box = []\n",
    "for h2 in all_h2:\n",
    "    a_tag = h2.find('a')\n",
    "    if a_tag:\n",
    "        href = a_tag.get('href')\n",
    "        link_f = 'https://stock.zhipianbang.com' + href\n",
    "        link_box.append( link_f )\n",
    "print( link_box )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caf4b0ec918f685a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "i = 1\n",
    "for link in link_box:\n",
    "    response_in = requests.get( link )\n",
    "    content_in = response_in.text \n",
    "    soup_in = BeautifulSoup( content_in, 'html.parser' )\n",
    "    music_head = soup_in.find( class_ = 'music_head' )\n",
    "    if music_head:\n",
    "        data_url = music_head.get('data-url')\n",
    "        print( data_url )\n",
    "        response_f = requests.get( data_url, headers = headers )   \n",
    "        if response_f.status_code == 200:\n",
    "            with open( f'../mp3/talk_sound/talk_sound{i}.mp3', 'wb') as file:\n",
    "                file.write(response_f.content)\n",
    "            print(f'MP3 file downloaded{i}')\n",
    "        else:\n",
    "            print(f\"Failed to retrieve MP3 file{i+1}. Status code:\", response.status_code)\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb1321140fa97163",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = requests.get('https://www.sucai999.com/search/audio/%E4%BA%A4%E8%B0%88.html', headers = headers )\n",
    "content = response.text\n",
    "soup = BeautifulSoup( content, 'html.parser' )\n",
    "all_class = soup.findAll( 'li', class_='list_item audio_item audioHandler' )\n",
    "\n",
    "link_box2 = []\n",
    "for k in all_class:\n",
    "    a_tag = k.find('a')\n",
    "    if a_tag:\n",
    "        href = a_tag.get('href')\n",
    "        link_f = 'https://www.sucai999.com' + href\n",
    "        link_box2.append( link_f )\n",
    "        \n",
    "# print( link_box2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22f99ecf9f7cfa5d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "i = 34\n",
    "for link in link_box:\n",
    "    response_in = requests.get( link )\n",
    "    content_in = response_in.text \n",
    "    soup_in = BeautifulSoup( content_in, 'html.parser' )\n",
    "    link_in = soup.find('source')\n",
    "    if link_in:\n",
    "        src = link_in.get('src')\n",
    "        link_f = 'https:' + src\n",
    "        print( link_f )\n",
    "        response_f = requests.get( link_f, headers = headers )   \n",
    "        if response_in.status_code == 200:\n",
    "            with open( f'../mp3/talk_sound/talk_sound{i}.mp3', 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f'MP3 file downloaded{i}')\n",
    "        else:\n",
    "            print(f\"Failed to retrieve MP3 file{i+1}. Status code:\", response.status_code)\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd39d06341de84c3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = requests.get('https://v.docin.com/search.do?source_type=2&pid=&nkey=%E4%BA%A4%E8%B0%88%E5%A3%B0', headers=headers)\n",
    "content = response.text\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "all_c = soup.findAll( class_='m-showlst-pic')\n",
    "link_box3 = []\n",
    "for c in all_c:\n",
    "    a_tag = c.find('a')\n",
    "    if a_tag:\n",
    "        href = a_tag.get('href')\n",
    "        link_f = 'https://v.docin.com' + href\n",
    "        link_box3.append(link_f)\n",
    "# print(link_box3)\n",
    "\n",
    "i = 34\n",
    "for link in link_box3:\n",
    "    print( link )\n",
    "    response_t = requests.get( link, headers=headers )\n",
    "    content_t = response_t.text\n",
    "    soup_t = BeautifulSoup( content_t, 'html.parser' )\n",
    "    c_all = soup_t.find( 'audio' )\n",
    "    print( c_all )\n",
    "    # music_head = soup_in.find( 'audio' )\n",
    "    if c_all:\n",
    "        data_url = 'https:' + c_all.get( 'src' )\n",
    "        print(data_url)\n",
    "        response_f = requests.get(data_url, headers=headers)\n",
    "        if response_f.status_code == 200:\n",
    "            with open(f'../mp3/talk_sound/talk_sound{i}.mp3', 'wb') as file:\n",
    "                file.write(response_f.content)\n",
    "            print(f'MP3 file downloaded{i}')\n",
    "        else:\n",
    "            print(f\"Failed to retrieve MP3 file{i + 1}. Status code:\", response.status_code)\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3001451d139dea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = requests.get('https://v.docin.com/search.do?source_type=2&pid=&nkey=%E6%B1%BD%E8%BD%A6%E9%B8%A3%E7%AC%9B', headers=headers)\n",
    "content = response.text\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "all_c = soup.findAll( class_='m-showlst-pic')\n",
    "link_box3 = []\n",
    "for c in all_c:\n",
    "    a_tag = c.find('a')\n",
    "    if a_tag:\n",
    "        href = a_tag.get('href')\n",
    "        link_f = 'https://v.docin.com' + href\n",
    "        link_box3.append(link_f)\n",
    "# print(link_box3)\n",
    "\n",
    "i = 37\n",
    "for link in link_box3:\n",
    "    print( link )\n",
    "    response_t = requests.get( link, headers=headers )\n",
    "    content_t = response_t.text\n",
    "    soup_t = BeautifulSoup( content_t, 'html.parser' )\n",
    "    c_all = soup_t.find( 'audio' )\n",
    "    print( c_all )\n",
    "    # music_head = soup_in.find( 'audio' )\n",
    "    if c_all:\n",
    "        data_url = 'https:' + c_all.get( 'src' )\n",
    "        print(data_url)\n",
    "        response_f = requests.get(data_url, headers=headers)\n",
    "        if response_f.status_code == 200:\n",
    "            with open(f'../mp3/car_sound/car_sound{i}.mp3', 'wb') as file:\n",
    "                file.write(response_f.content)\n",
    "            print(f'MP3 file downloaded{i}')\n",
    "        else:\n",
    "            print(f\"Failed to retrieve MP3 file{i + 1}. Status code:\", response.status_code)\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f55adcfb1dbe4fb5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = requests.get('https://v.docin.com/search.do?nkey=%E6%B1%BD%E8%BD%A6%E9%B8%A3%E7%AC%9B&source_type=2&curPage=2', headers=headers)\n",
    "content = response.text\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "all_c = soup.findAll( class_='m-showlst-pic')\n",
    "link_box3 = []\n",
    "for c in all_c:\n",
    "    a_tag = c.find('a')\n",
    "    if a_tag:\n",
    "        href = a_tag.get('href')\n",
    "        link_f = 'https://v.docin.com' + href\n",
    "        link_box3.append(link_f)\n",
    "# print(link_box3)\n",
    "\n",
    "i = 76\n",
    "for link in link_box3:\n",
    "    print( link )\n",
    "    response_t = requests.get( link, headers=headers )\n",
    "    content_t = response_t.text\n",
    "    soup_t = BeautifulSoup( content_t, 'html.parser' )\n",
    "    c_all = soup_t.find( 'audio' )\n",
    "    print( c_all )\n",
    "    # music_head = soup_in.find( 'audio' )\n",
    "    if c_all:\n",
    "        data_url = 'https:' + c_all.get( 'src' )\n",
    "        print(data_url)\n",
    "        response_f = requests.get(data_url, headers=headers)\n",
    "        if response_f.status_code == 200:\n",
    "            with open(f'../mp3/car_sound/car_sound{i}.mp3', 'wb') as file:\n",
    "                file.write(response_f.content)\n",
    "            print(f'MP3 file downloaded{i}')\n",
    "        else:\n",
    "            print(f\"Failed to retrieve MP3 file{i + 1}. Status code:\", response.status_code)\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93ae2b6a65d55dbd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = requests.get('https://aspx.sc.chinaz.com/query.aspx?keyWord=%E6%B1%BD%E8%BD%A6%E9%B8%A3%E7%AC%9B&classid=14&navindex=0', headers=headers )\n",
    "content = response.text\n",
    "soup = BeautifulSoup( content, 'html.parser' )\n",
    "all_c = soup.findAll( class_ = 'im' )\n",
    "link_box4 = []\n",
    "for c in all_c:\n",
    "    a_tag = c.find('a')\n",
    "    if a_tag:\n",
    "        href = a_tag.get('href')\n",
    "        link_box4.append( href )\n",
    "print(link_box4)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae4a43ec53239513",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "i = 1\n",
    "for link in link_box4:\n",
    "    response_t = requests.get( link, headers=headers )\n",
    "    content_t = response_t.text\n",
    "    soup_t = BeautifulSoup( content_t, 'html.parser' )\n",
    "    c_all = soup_t.find( 'source' )\n",
    "    print( c_all )\n",
    "    if c_all:\n",
    "        data_url = 'https:' + c_all.get( 'src' )\n",
    "        print( data_url )\n",
    "        response_f = requests.get(data_url, headers=headers)\n",
    "        if response_f.status_code == 200:\n",
    "            with open(f'./test/car_sound{i}.mp3', 'wb') as file:\n",
    "                file.write(response_f.content)\n",
    "            print(f'MP3 file downloaded{i}')\n",
    "        else:\n",
    "            print(f\"Failed to retrieve MP3 file{i + 1}. Status code:\", response.status_code)\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec74495ea98c4803",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bb6ff8e106b654d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
