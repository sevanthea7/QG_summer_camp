{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-26T14:25:28.405014900Z",
     "start_time": "2024-07-26T14:25:23.381544200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        residual = self.downsample(residual)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T14:25:32.973914800Z",
     "start_time": "2024-07-26T14:25:32.960138100Z"
    }
   },
   "id": "19fb8d35d5300e1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nclass Net(nn.Module):\\n    def __init__(self, num_classes=5):\\n        super(Net, self).__init__()\\n        self.features = nn.Sequential(\\n            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\\n            nn.ReLU(inplace=True),\\n            nn.MaxPool2d(kernel_size=3, stride=2),\\n            \\n            Bottleneck(96, 32, 128),\\n            \\n            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\\n            nn.ReLU(inplace=True),\\n            nn.MaxPool2d(kernel_size=3, stride=2),\\n            \\n            Bottleneck(256, 64, 256),\\n            \\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\\n            nn.ReLU(inplace=True),\\n            \\n            Bottleneck(512, 128, 512),\\n            \\n            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\\n            # nn.ReLU(inplace=True),\\n            # nn.MaxPool2d(kernel_size=3, stride=2),\\n\\n            # Bottleneck(384, 128, 512), \\n            \\n            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\\n            nn.ReLU(inplace=True),\\n            \\n            Bottleneck(1024, 256, 1024),\\n            \\n            nn.Conv2d(1024, 1280, kernel_size=3, stride=1, padding=1),\\n            nn.ReLU(inplace=True),\\n            \\n            nn.AdaptiveAvgPool2d((1, 1)),\\n        )\\n        \\n        self.classifier = nn.Sequential(\\n            nn.Dropout(0.5),\\n            nn.Linear(1280, 1024),\\n            nn.ReLU(inplace=True),\\n            nn.Dropout(0.5),\\n            nn.Linear(1024, 256),\\n            nn.ReLU(inplace=True),\\n            nn.Linear(256, num_classes)\\n        )\\n\\n    def forward(self, x):\\n        x = self.features(x)\\n        x = x.view(x.size(0), -1)\\n        x = self.classifier(x)\\n        return x\\n        \\n\\n\\n\\n\\n\\nclass Net(nn.Module):\\n    def __init__(self, num_classes=5):\\n        super(Net, self).__init__()\\n        self.features = nn.Sequential(\\n            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\\n            nn.ReLU(inplace=True),\\n            nn.MaxPool2d(kernel_size=3, stride=2),\\n            \\n            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\\n            nn.ReLU(inplace=True),\\n            nn.MaxPool2d(kernel_size=3, stride=2),\\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\\n            nn.ReLU(inplace=True),\\n            \\n            Bottleneck(512, 128, 512),\\n            \\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\\n            nn.ReLU(inplace=True),\\n            nn.MaxPool2d(kernel_size=3, stride=2),\\n        \\n            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\\n            nn.ReLU(inplace=True),\\n            \\n            Bottleneck(1024, 256, 1024),  # 第五个残差块\\n            \\n            nn.Conv2d(1024, 1280, kernel_size=3, stride=1, padding=1),\\n            nn.ReLU(inplace=True),\\n            nn.AdaptiveAvgPool2d((3, 3)),\\n        )\\n        \\n        self.classifier = nn.Sequential(\\n            nn.Dropout(0.5),\\n            nn.Linear(1280*3*3, 2048),\\n            nn.ReLU(inplace=True),\\n            nn.Dropout(0.5),\\n            nn.Linear(2048, 1024),\\n            nn.ReLU(inplace=True),\\n            nn.Dropout(0.5),\\n            nn.Linear(1024, 256),\\n            nn.ReLU(inplace=True),\\n            nn.Dropout(0.5),\\n            nn.Linear(256, 128),\\n            nn.ReLU(inplace=True),\\n            nn.Linear(128, num_classes)\\n        )\\n        self.residual_block = Bottleneck( 512, 256, 512 )\\n\\n    def forward(self, x):\\n        x = self.features(x)\\n        \\n        x = x.view(x.size(0), -1)\\n        x = self.classifier(x)\\n        return x\\n        \\n        \\n\\n\\nnet = Net(num_classes=5)\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n'"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            Bottleneck(96, 32, 128),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            Bottleneck(256, 64, 256),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            Bottleneck(512, 128, 512),\n",
    "            \n",
    "            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            # Bottleneck(384, 128, 512), \n",
    "            \n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            Bottleneck(1024, 256, 1024),\n",
    "            \n",
    "            nn.Conv2d(1024, 1280, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1280, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            Bottleneck(512, 128, 512),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        \n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            Bottleneck(1024, 256, 1024),\n",
    "            \n",
    "            nn.Conv2d(1024, 1280, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((3, 3)),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1280*3*3, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self.residual_block = Bottleneck( 512, 256, 512 )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "net = Net(num_classes=5)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T14:23:45.141965200Z",
     "start_time": "2024-07-23T14:23:45.117381300Z"
    }
   },
   "id": "42dab0c51012fa3",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            Bottleneck(96, 32, 128),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            Bottleneck(256, 64, 512),\n",
    "            \n",
    "            nn.Conv2d(512, 768, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            Bottleneck(768, 128, 768),\n",
    "            \n",
    "            nn.Conv2d(768, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            Bottleneck(1024, 128, 1280), \n",
    "            \n",
    "            # nn.Conv2d(1024, 768, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Bottleneck(768, 256, 1024),\n",
    "            \n",
    "            # nn.Conv2d(1024, 1280, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Bottleneck(1536, 320, 2048),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1280, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "net = Net(num_classes=5)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T14:25:37.619289Z",
     "start_time": "2024-07-26T14:25:37.533288100Z"
    }
   },
   "id": "dbf839197337d615",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train loss: 100%[ ************************************************** ->  ]0.940\n",
      "[epoch 1] train_loss: 195.578    test_accuracy: 0.607\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]1.334\n",
      "[epoch 2] train_loss: 183.206    test_accuracy: 0.615\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.759\n",
      "[epoch 3] train_loss: 177.270    test_accuracy: 0.622\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.885\n",
      "[epoch 4] train_loss: 173.003    test_accuracy: 0.635\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.866\n",
      "[epoch 5] train_loss: 167.544    test_accuracy: 0.635\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.936\n",
      "[epoch 6] train_loss: 165.434    test_accuracy: 0.645\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]1.204\n",
      "[epoch 7] train_loss: 164.434    test_accuracy: 0.635\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.867\n",
      "[epoch 8] train_loss: 156.703    test_accuracy: 0.660\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.841\n",
      "[epoch 9] train_loss: 155.485    test_accuracy: 0.668\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.923\n",
      "[epoch 10] train_loss: 152.855    test_accuracy: 0.667\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]1.332\n",
      "[epoch 11] train_loss: 151.243    test_accuracy: 0.637\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]1.075\n",
      "[epoch 12] train_loss: 152.024    test_accuracy: 0.672\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.684\n",
      "[epoch 13] train_loss: 150.245    test_accuracy: 0.667\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]1.003\n",
      "[epoch 14] train_loss: 146.177    test_accuracy: 0.663\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]1.207\n",
      "[epoch 15] train_loss: 146.806    test_accuracy: 0.682\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.779\n",
      "[epoch 16] train_loss: 144.284    test_accuracy: 0.687\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.648\n",
      "[epoch 17] train_loss: 143.851    test_accuracy: 0.697\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.827\n",
      "[epoch 18] train_loss: 142.557    test_accuracy: 0.692\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.700\n",
      "[epoch 19] train_loss: 145.811    test_accuracy: 0.678\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.838\n",
      "[epoch 20] train_loss: 139.067    test_accuracy: 0.725\n",
      "finished\n",
      " train loss: 100%[ ************************************************** ->  ]0.713\n",
      "[epoch 21] train_loss: 139.661    test_accuracy: 0.692\n",
      "finished\n",
      " train loss: 18 %[ ********* -> ........................................ ]0.777"
     ]
    }
   ],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, csv_f, img_folder, transform, s_num=6000):\n",
    "        self.img_labels = pd.read_csv(csv_f)[:s_num]\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(self.img_labels.iloc[idx, 0])\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        img_path = os.path.join(self.img_folder, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "pre = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                          transforms.RandomHorizontalFlip(),\n",
    "                          transforms.RandomRotation(15),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                          ])\n",
    "\n",
    "csv_f = '../data/cassava-leaf-disease-classification/train.csv'\n",
    "img_folder = '../data/cassava-leaf-disease-classification/train_images'\n",
    "data = CassavaDataset(csv_f, img_folder, transform=pre, s_num=6000)\n",
    "\n",
    "train_size = int(0.9 * len(data))\n",
    "train_dataset, test_dataset = random_split(data, [train_size, (len(data) - train_size)])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "num_classes = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#net = Net( num_classes= 5)\n",
    "net.to(device)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "t_steps = len(trainloader)\n",
    "test_num = len(test_dataset)\n",
    "\n",
    "for epoch in range( 32 ):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for step, data in enumerate(trainloader, start=0):\n",
    "        imgs, labels = data\n",
    "        rate = ((step + 1) / t_steps)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(imgs.to(device))\n",
    "        loss = loss_f(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        a = '*' * int(rate * 50)\n",
    "        b = '.' * int((1 - rate) * 50)\n",
    "        print('\\r train loss: {:^3.0f}%[ {} -> {} ]{:.3f}'.format(int(rate * 100), a, b, loss), end='')\n",
    "    print()\n",
    "\n",
    "    net.eval()\n",
    "    r = 0.0\n",
    "    best_R = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data_test in testloader:\n",
    "            t_img, t_lbl = data_test\n",
    "            outputs = net(t_img.to(device))\n",
    "            pred_y = torch.max(outputs, dim=1)[1]\n",
    "            r += (pred_y == t_lbl.to(device)).sum().item()\n",
    "        acc_R = r / test_num\n",
    "        if acc_R > best_R:\n",
    "            best_R = acc_R\n",
    "            torch.save(net.state_dict(), '../path/Net_best.pth')\n",
    "        print('[epoch %d] train_loss: %.3f    test_accuracy: %.3f' % (epoch + 1, running_loss, acc_R))\n",
    "\n",
    "    print('finished')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-23T14:23:45.206324200Z"
    }
   },
   "id": "9f19771ad748dcfc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Cassava Mosaic Disease (CMD) 0.9340549111366272\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                                   )\n",
    "img = Image.open('../data/cassava-leaf-disease-classification/test_images/2216849948.jpg')\n",
    "# plt.imshow(img)\n",
    "import json\n",
    "\n",
    "img = img_transform(img)\n",
    "img = torch.unsqueeze(img, dim=0)\n",
    "\n",
    "with open('../data/cassava-leaf-disease-classification/label_num_to_disease_map.json', 'r') as f:\n",
    "    sorted_class = json.load(f)\n",
    "# print(sorted_class)\n",
    "net.load_state_dict(torch.load('../model/725Net_best.pth'))\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = torch.squeeze(net(img))\n",
    "    predict = torch.softmax(output, dim=0)\n",
    "    p_class = torch.argmax(predict).numpy()\n",
    "    print(p_class, sorted_class[str(p_class)], predict[p_class].item())\n",
    "\n",
    "import csv\n",
    "\n",
    "output_path = 'submission.csv'\n",
    "with open(output_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['image_id', 'label'])\n",
    "    writer.writerow(['2216849948.jpg', p_class])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T14:26:12.362716200Z",
     "start_time": "2024-07-26T14:26:12.147735200Z"
    }
   },
   "id": "fe74e02d4561154b",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "img_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                                   )\n",
    "test_images_path = '../data/cassava-leaf-disease-classification/test_images'\n",
    "test_images = os.listdir( test_images_path )\n",
    "net.eval()\n",
    "predictions = []\n",
    "\n",
    "'''\n",
    "with open('../data/cassava-leaf-disease-classification/label_num_to_disease_map.json', 'r') as f:\n",
    "    sorted_class = json.load(f)\n",
    "'''\n",
    "net.load_state_dict(torch.load('../path/Net_best.pth'))\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image_name in test_images:\n",
    "        img_path = os.path.join( test_images_path, image_name )\n",
    "        img = Image.open( img_path ).convert( 'RGB' )\n",
    "        img = img_transform( img )\n",
    "        img = torch.unsqueeze( img, dim=0 ).to( device )\n",
    "        output = net( img )\n",
    "        _, predicted = torch.max( output, 1 )\n",
    "        predictions.append( (image_name, predicted.item()) )\n",
    "\n",
    "        \n",
    "        \n",
    "submission_df = pd.DataFrame( predictions, columns = [ 'image_id', 'label' ] )\n",
    "\n",
    "submission_df.to_csv( 'submission.csv', index = False )"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "addbe1869be4ac13",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''KAGGLE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes = 5 ):\n",
    "        super( Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 512, kernel_size=3, stride=1, padding=1),  # 增加卷积核数量\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 第二部分：ResNet的残差块\n",
    "        self.residual_block = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        identity = x\n",
    "        out = self.residual_block(x)\n",
    "        x = F.relu(out + identity)\n",
    "        x = x.view(x.size(0), 512 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(num_classes=5)\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, csv_f, img_folder, transform, s_num=4000):\n",
    "        self.img_labels = pd.read_csv(csv_f)[:s_num]\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(self.img_labels.iloc[idx, 0])\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        img_path = os.path.join(self.img_folder, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "pre = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                          transforms.RandomHorizontalFlip(),\n",
    "                          transforms.RandomRotation(15),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                          ])\n",
    "\n",
    "csv_f = '/kaggle/input/cassava-leaf-disease-classification/train.csv'\n",
    "img_folder = '/kaggle/input/cassava-leaf-disease-classification/train_images'\n",
    "data = CassavaDataset(csv_f, img_folder, transform=pre, s_num=8000)\n",
    "\n",
    "train_size = int(0.9 * len(data))\n",
    "train_dataset, test_dataset = random_split(data, [train_size, (len(data) - train_size)])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "num_classes = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "#net = Net( num_classes= 5)\n",
    "net.to(device)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "t_steps = len(trainloader)\n",
    "test_num = len(test_dataset)\n",
    "\n",
    "for epoch in range(5):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for step, data in enumerate(trainloader, start=0):\n",
    "        imgs, labels = data\n",
    "        rate = ((step + 1) / t_steps)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(imgs.to(device))\n",
    "        loss = loss_f(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        a = '*' * int(rate * 50)\n",
    "        b = '.' * int((1 - rate) * 50)\n",
    "        print('\\r train loss: {:^3.0f}%[ {} -> {} ]{:.3f}'.format(int(rate * 100), a, b, loss), end='')\n",
    "    print()\n",
    "\n",
    "    net.eval()\n",
    "    r = 0.0\n",
    "    best_R = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data_test in testloader:\n",
    "            t_img, t_lbl = data_test\n",
    "            outputs = net(t_img.to(device))\n",
    "            pred_y = torch.max(outputs, dim=1)[1]\n",
    "            r += (pred_y == t_lbl.to(device)).sum().item()\n",
    "        acc_R = r / test_num\n",
    "        if acc_R > best_R:\n",
    "            best_R = acc_R\n",
    "            torch.save(net.state_dict(), '/kaggle/working/Net_best.pth')\n",
    "        print('[epoch %d] train_loss: %.3f    test_accuracy: %.3f' % (epoch + 1, running_loss, acc_R))\n",
    "\n",
    "    print('finished')\n",
    "    \n",
    "img_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                                   )\n",
    "test_images_path = '/kaggle/input/cassava-leaf-disease-classification/test_image'\n",
    "test_images = os.listdir( test_images_path )\n",
    "net.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image_name in test_images:\n",
    "        img_path = os.path.join( test_images_path, image_name )\n",
    "        img = Image.open( img_path ).convert( 'RGB' )\n",
    "        img = img_transform( img )\n",
    "        img = torch.unsqueeze( img, dim=0 ).to( device )\n",
    "        output = net( img )\n",
    "        _, predicted = torch.max( output, 1 )\n",
    "        predictions.append( (image_name, predicted.item()) )\n",
    "\n",
    "        \n",
    "        \n",
    "submission_df = pd.DataFrame( predictions, columns = [ 'image_id', 'label' ] )\n",
    "\n",
    "submission_df.to_csv( '/kaggle/working/submission.csv', index = False )\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9ae43e7303434dcf",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
