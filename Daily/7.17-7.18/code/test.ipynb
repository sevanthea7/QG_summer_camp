{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-18T10:59:18.579183700Z",
     "start_time": "2024-07-18T10:59:18.201060400Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch._dynamo' has no attribute 'trace_rules' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader, Dataset, random_split\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms, datasets\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\__init__.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodulefinder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Module\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mextension\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _HAS_OPS\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malexnet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvnext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdensenet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mefficientnet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\convnext.py:9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functional \u001B[38;5;28;01mas\u001B[39;00m F\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmisc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Conv2dNormActivation, Permute\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstochastic_depth\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StochasticDepth\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_presets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ImageClassification\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _log_api_usage_once\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\ops\\__init__.py:23\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgiou_loss\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m generalized_box_iou_loss\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmisc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpoolers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MultiScaleRoIAlign\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mps_roi_align\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ps_roi_align, PSRoIAlign\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mps_roi_pool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\ops\\poolers.py:10\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mboxes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m box_area\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _log_api_usage_once\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mroi_align\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m roi_align\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# is not supported by ONNX tracing yet.\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# that merges the levels to the right indices\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39munused\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_onnx_merge_levels\u001B[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\ops\\roi_align.py:4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m List, Union\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_dynamo\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn, Tensor\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_dynamo\\__init__.py:64\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mjit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_builtins\u001B[39;00m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;66;03m# Wrap manual_seed with the disable decorator.\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# Can't do it at its implementation due to dependency issues.\u001B[39;00m\n\u001B[1;32m---> 64\u001B[0m torch\u001B[38;5;241m.\u001B[39mmanual_seed \u001B[38;5;241m=\u001B[39m disable(torch\u001B[38;5;241m.\u001B[39mmanual_seed)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# Add the new manual_seed to the builtin registry.\u001B[39;00m\n\u001B[0;32m     66\u001B[0m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39m_builtins\u001B[38;5;241m.\u001B[39m_register_builtin(torch\u001B[38;5;241m.\u001B[39mmanual_seed, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maten::manual_seed\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_dynamo\\decorators.py:50\u001B[0m, in \u001B[0;36mdisable\u001B[1;34m(fn, recursive)\u001B[0m\n\u001B[0;32m     48\u001B[0m         fn \u001B[38;5;241m=\u001B[39m innermost_fn(fn)\n\u001B[0;32m     49\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(fn)\n\u001B[1;32m---> 50\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m DisableContext()(fn)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DisableContext()\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_dynamo\\eval_frame.py:410\u001B[0m, in \u001B[0;36m_TorchDynamoContext.__call__\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    408\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m--> 410\u001B[0m     (filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m trace_rules\u001B[38;5;241m.\u001B[39mcheck(fn))\n\u001B[0;32m    411\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[0;32m    412\u001B[0m         \u001B[38;5;28mgetattr\u001B[39m(fn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__name__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_call_impl\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_wrapped_call_impl\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    413\u001B[0m     )\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m filename \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m DONT_WRAP_FILES\n\u001B[0;32m    415\u001B[0m ):\n\u001B[0;32m    416\u001B[0m     \u001B[38;5;66;03m# call to a builtin without a frame for us to capture\u001B[39;00m\n\u001B[0;32m    417\u001B[0m     fn \u001B[38;5;241m=\u001B[39m external_utils\u001B[38;5;241m.\u001B[39mwrap_inline(fn)\n\u001B[0;32m    419\u001B[0m callback \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_dynamo\\trace_rules.py:3378\u001B[0m, in \u001B[0;36mcheck\u001B[1;34m(obj, is_inlined_call)\u001B[0m\n\u001B[0;32m   3377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck\u001B[39m(obj, is_inlined_call\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m-> 3378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m check_verbose(obj, is_inlined_call)\u001B[38;5;241m.\u001B[39mskipped\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_dynamo\\trace_rules.py:3361\u001B[0m, in \u001B[0;36mcheck_verbose\u001B[1;34m(obj, is_inlined_call)\u001B[0m\n\u001B[0;32m   3358\u001B[0m     fi \u001B[38;5;241m=\u001B[39m FunctionInfo(obj, \u001B[38;5;28;01mNone\u001B[39;00m, getfile(obj), \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   3360\u001B[0m \u001B[38;5;66;03m# Consulte the central trace rules defined in torch._dynamo.trace_rules.\u001B[39;00m\n\u001B[1;32m-> 3361\u001B[0m rule \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mtrace_rules\u001B[38;5;241m.\u001B[39mlookup_inner(\n\u001B[0;32m   3362\u001B[0m     fi\u001B[38;5;241m.\u001B[39mpy_obj, fi\u001B[38;5;241m.\u001B[39mname, fi\u001B[38;5;241m.\u001B[39mfilename, is_inlined_call\n\u001B[0;32m   3363\u001B[0m )\n\u001B[0;32m   3364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m rule \u001B[38;5;129;01min\u001B[39;00m [UserFunctionVariable, FunctorchHigherOrderVariable]:\n\u001B[0;32m   3365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SkipResult(\n\u001B[0;32m   3366\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   3367\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minlined according trace_rules.lookup\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3368\u001B[0m     )\n",
      "\u001B[1;31mAttributeError\u001B[0m: partially initialized module 'torch._dynamo' has no attribute 'trace_rules' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 定义残差块\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# 定义截取的 AlexNet 部分\n",
    "class AlexNetPartial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNetPartial, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),  # 新增的卷积层\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),  # 新增的卷积层\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "# 定义部分 ResNet（仅包含残差块）\n",
    "class ResNetPartial(nn.Module):\n",
    "    def __init__(self, block, num_blocks):\n",
    "        super(ResNetPartial, self).__init__()\n",
    "        self.in_planes = 128  # 确保与 AlexNet 的输出通道数一致\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 128, num_blocks[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 512, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        return x\n",
    "\n",
    "# 定义组合网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super( Net, self).__init__()\n",
    "        self.alexnet_partial = AlexNetPartial()\n",
    "        self.resnet_partial = ResNetPartial(BasicBlock, [2, 2, 2, 2])\n",
    "        self.fc = nn.Linear(512, 5)  # 输出5个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alexnet_partial(x)\n",
    "        x = self.resnet_partial(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, csv_f, img_folder, transform, s_num=4000):\n",
    "        self.img_labels = pd.read_csv(csv_f)[:s_num]\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(self.img_labels.iloc[idx, 0])\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        img_path = os.path.join(self.img_folder, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "pre = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                          transforms.RandomHorizontalFlip(),\n",
    "                          transforms.RandomRotation(15),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                          ])\n",
    "\n",
    "csv_f = '../data/cassava-leaf-disease-classification/train.csv'\n",
    "img_folder = '../data/cassava-leaf-disease-classification/train_images'\n",
    "data = CassavaDataset(csv_f, img_folder, transform=pre, s_num=4000)\n",
    "\n",
    "train_size = int(0.9 * len(data))\n",
    "train_dataset, test_dataset = random_split(data, [train_size, (len(data) - train_size)])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "num_classes = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "t_steps = len(trainloader)\n",
    "test_num = len(test_dataset)\n",
    "\n",
    "for epoch in range(5):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for step, data in enumerate(trainloader, start=0):\n",
    "        imgs, labels = data\n",
    "        rate = ((step + 1) / t_steps)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(imgs.to(device))\n",
    "        loss = loss_f(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        a = '*' * int(rate * 50)\n",
    "        b = '.' * int((1 - rate) * 50)\n",
    "        print('\\r train loss: {:^3.0f}%[ {} -> {} ]{:.3f}'.format(int(rate * 100), a, b, loss), end='')\n",
    "    print()\n",
    "\n",
    "    net.eval()\n",
    "    r = 0.0\n",
    "    best_R = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data_test in testloader:\n",
    "            t_img, t_lbl = data_test\n",
    "            outputs = net(t_img.to(device))\n",
    "            pred_y = torch.max(outputs, dim=1)[1]\n",
    "            r += (pred_y == t_lbl.to(device)).sum().item()\n",
    "        acc_R = r / test_num\n",
    "        if acc_R > best_R:\n",
    "            best_R = acc_R\n",
    "            torch.save(net.state_dict(), '../path/Net_best.pth')\n",
    "        print('[epoch %d] train_loss: %.3f    test_accuracy: %.3f' % (epoch + 1, running_loss, acc_R))\n",
    "\n",
    "    print('finished')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-18T10:59:18.574362300Z"
    }
   },
   "id": "70efcd952b0983c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
