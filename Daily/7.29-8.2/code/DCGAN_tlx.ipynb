{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorlayerx as tlx\n",
    "import tensorlayerx.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://sevanthea7.oss-cn-beijing.aliyuncs.com/QGworks/202407311038932.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "944c451a075147e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Generator( nn.Module ):\n",
    "    gen_features = 64\n",
    "    dis_features = 64\n",
    "    size16 = dis_features // 16                             # 4 -> 特征图的大小\n",
    "    w_init = nn.initializers.random_normal( 0, 0.02 )       # 权重初始化，使用均值为0，标准差为0.02的正态分布\n",
    "    g_init = nn.initializers.random_normal( 1., 0.02 )      # 偏置初始化，使用均值为1，标准差为0.02的正态分布\n",
    "    def __init__( self ):\n",
    "        super( Generator, self ).__init__()\n",
    "        self.fc1 = nn.Linear( \n",
    "            out_features = self.gen_features * 8 * self.size16 * self.size16, # 512 * 4 * 4\n",
    "            W_init = self.w_init,\n",
    "            b_init = None\n",
    "        )\n",
    "        self.reshape = nn.Reshape( \n",
    "            shape = ( -1, self.size16, self.size16, self.gen_features * 8 )\n",
    "        )\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d( 0.9, act = nn.ReLU, gamma_init = self.g_init )\n",
    "        self.deconv2d1 = nn.ConvTranspose2d( \n",
    "            out_channels = self.gen_features * 4,\n",
    "            kernel_size = ( 5, 5 ),\n",
    "            stride = ( 2, 2 ),\n",
    "            W_init = self.w_init,\n",
    "            b_init = None\n",
    "        )\n",
    "        '''\n",
    "        输入：[ N, 512, 4, 4 ]\n",
    "        输出高度：( 4 - 1 ) * 2 + 5 = 11\n",
    "        输出宽度：( 4 - 1 ) * 2 + 5 = 11\n",
    "        -> 输出[ N, 256, 11, 11 ]\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d( 0.9, act = nn.ReLU, gamma_init = self.g_init )\n",
    "        self.deconv2d2 = nn.ConvTranspose2d(\n",
    "            out_channels = self.gen_features * 2,\n",
    "            kernel_size = ( 5, 5 ),\n",
    "            stride = ( 2, 2 ), \n",
    "            W_init = self.w_init,\n",
    "            b_init = None\n",
    "        )\n",
    "        '''\n",
    "        [ N, 256, 11, 11 ]\n",
    "        ( 11 - 1 ) * 2 + 5 = 25\n",
    "        -> [ N, 128, 25, 25 ]\n",
    "        '''\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm2d( 0.9, act = nn.ReLU, gamma_init = self.g_init )\n",
    "        self.deconv2d3 = nn.ConvTranspose2d(\n",
    "            out_channels = self.gen_features,\n",
    "            kernel_size = ( 5, 5 ),\n",
    "            stride = ( 2, 2 ),\n",
    "            W_init = self.w_init,\n",
    "            b_init = None\n",
    "        )\n",
    "        '''\n",
    "        [ N, 128, 25, 25 ]\n",
    "        ( 25 - 1 ) * 2 + 5 = 53\n",
    "        -> [ N, 64, 53, 53 ]\n",
    "        '''\n",
    "        \n",
    "        self.bn4 = nn.BatchNorm2d( 0.9, act = nn.ReLU, gamma_init = self.g_init )\n",
    "        self.deconv2d4 = nn.ConvTranspose2d(\n",
    "            out_channels = 3,\n",
    "            kernel_size = ( 5, 5 ),\n",
    "            stride = ( 2, 2 ),\n",
    "            W_init = self.w_init,\n",
    "            b_init = None\n",
    "        )\n",
    "        '''\n",
    "        [ N, 64, 53, 53 ]\n",
    "        ( 53 - 1 ) * 2 + 5 = 109\n",
    "        -> [ N, 3, 109, 109 ]\n",
    "        '''\n",
    "    \n",
    "    def forward( self, x ):\n",
    "        x = self.fc1( x )\n",
    "        x = self.reshape( x )\n",
    "        \n",
    "        x = self.bn1( x )\n",
    "        x = self.deconv2d1( x )\n",
    "        x = self.bn2( x )\n",
    "        x = self.deconv2d2( x )\n",
    "        x = self.bn3( x )\n",
    "        x = self.deconv2d3( x )\n",
    "        x = self.bn4( x )\n",
    "        x = self.deconv2d4( x )\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd02af43e97f436c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "反卷积公式\n",
    "$$\n",
    "H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{kernel_size}[0] + \\text{output\\_padding}[0]\\\\\n",
    "W_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{kernel_size}[1] + \\text{output\\_padding}[1]\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bfd3790f85628ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Discriminator( nn.Module ):\n",
    "    dis_features = 64\n",
    "    w_init = nn.initializers.random_normal( 0.02 )\n",
    "    g_init = nn.initializers.random_normal( 1., 0.02 )\n",
    "    \n",
    "    def __init__( self ):\n",
    "        super( Discriminator, self ).__init__()\n",
    "        self.conv1 = nn.Conv2d( \n",
    "            out_channels = self.dis_features,\n",
    "            kernel_size = ( 5, 5 ),\n",
    "            stride = ( 2, 2 ),\n",
    "            act = nn.LeakyReLU( 0.2 ),\n",
    "            W_init = self.w_init\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels = self.dis_features * 2,\n",
    "            kernel_size = ( 5, 5 ),\n",
    "            stride = ( 2, 2 ),\n",
    "            W_init = self.w_init,\n",
    "            b_init = None\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d( 0.9, act = nn.LeakyReLU( 0.2 ), gamma_init = self.g_init )\n",
    "        \n",
    "        self.conv3 = nn.Conv2d( \n",
    "            out_channels = self.dis_features * 4,\n",
    "            kernel_size = ( 5, 5 ),\n",
    "            stride = ( 2, 2 ),\n",
    "            W_init = self.w_init,\n",
    "            b_init = None\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d( 0.9, act = nn.LeakyReLU( 0.2 ), gamma_init = self.g_init )\n",
    "        \n",
    "        self.conv4 = nn.Conv2d( \n",
    "            out_channels = self.dis_features * 8,\n",
    "            kernel_size = ( 5, 5 ),\n",
    "            stride = ( 2, 2 ),\n",
    "            W_init = self.w_init,\n",
    "            b_init = None\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d( 0.9, act = nn.LeakyReLU( 0.2 ), gamma_init = self.g_init )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear( 1, self.w_init )\n",
    "        \n",
    "    \n",
    "    def forward( self, x ):\n",
    "        x = self.conv1( x )\n",
    "        x = self.conv2( x )\n",
    "        x = self.bn1( x )\n",
    "        x = self.conv3( x )\n",
    "        x = self.bn2( x )\n",
    "        x = self.conv4( x )\n",
    "        x = self.bn3( x )\n",
    "        \n",
    "        x = self.flatten( x )\n",
    "        x = self.fc( x )\n",
    "        \n",
    "        return x "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ca1e2d7112eb80d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e1af4371f07f616"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorboardX import transforems, load_images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b6cc395b3aa9f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cc8e77baf9015a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Dis_Loss( nn.Module ):\n",
    "    def __init__( self, Dis, Gen ):\n",
    "        super( Dis_Loss, self ).__init__()\n",
    "        self.Dis = Dis\n",
    "        self.Gen = Gen\n",
    "    \n",
    "    def forward( self, images, fake ):\n",
    "        dis_logits_f = self.Dis( self.Gen( fake ) )\n",
    "        dis_logits_r = self.Dis( images )\n",
    "        dis_loss_real = tlx.losses.sigmoid_cross_entropy( dis_logits_r, tlx.ones_like( dis_logits_r ) )\n",
    "        dis_loss_fake = tlx.losses.sigmoid_cross_entropy( dis_logits_f, tlx.zeros_like( dis_logits_f ) )\n",
    "        dis_loss = dis_loss_real + dis_loss_fake\n",
    "        return dis_loss\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e82feb4fec8d3bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Gen_Loss( nn.Module ):\n",
    "    def __init__( self, Dis, Gen ):\n",
    "        super( Gen_Loss, self ).__init__()\n",
    "        self.Dis = Dis\n",
    "        self.Gen = Gen\n",
    "        \n",
    "    def forward( self, images, fake ):\n",
    "        dis_logits = self.Dis( self.Gen( fake ) )\n",
    "        gen_loss = tlx.losses.sigmoid_cross_entropy( dis_logits, tlx.ones_like( dis_logits ) )\n",
    "        return gen_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0d9d3ac65be1c93"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_epoch = 25\n",
    "num_noise = 100\n",
    "num_batch = 32\n",
    "num_output = 64\n",
    "sample_size = 64\n",
    "num_tiles = int( np.sqrt( sample_size ) )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3deed91c388c6b44"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorlayerx.model import TrainOneStep\n",
    "from tensorlayerx.utils.visualize import save_images\n",
    "from MyData import get_celebA\n",
    "def train():\n",
    "    \n",
    "    images_loader, images_path = get_celebA( num_batch )              #从自定义的的数据集导入数据\n",
    "    \n",
    "    \n",
    "    Gen = Generator()\n",
    "    Dis = Discriminator()\n",
    "    Gen.init_build( nn.Input( shape = ( num_batch, 100 ) ) )\n",
    "    Dis.init_build( nn.Input( shape = ( num_batch, 64, 64, 3 ) ) )\n",
    "    \n",
    "    Gen.set_train()\n",
    "    Dis.set_train()\n",
    "    \n",
    "    dis_optimizer = tlx.optimizers.Adam( lr = 0.0002, beta_1 = 0.5 )\n",
    "    gen_optimizer = tlx.optimizers.Adam( lr = 0.0002, beta_1 = 0.5 )\n",
    "    \n",
    "    g_w = Gen.trainable_weights()\n",
    "    d_w = Dis.trainable_weights()\n",
    "    \n",
    "    net_loss_Dis = Dis_Loss( Gen, Dis )\n",
    "    net_loss_Gen = Gen_Loss( Gen, Dis )\n",
    "    \n",
    "    train_Gen = TrainOneStep( net_loss_Gen, optimizer = gen_optimizer, train_weights = g_w )\n",
    "    train_Dis = TrainOneStep( net_loss_Dis, optimizer = dis_optimizer, train_weights = d_w )\n",
    "    \n",
    "    for epoch in range( num_epoch ):\n",
    "        for i, batch in enumerate( images_loader ):\n",
    "            # z -> noise 0到1之间的随机噪声\n",
    "            z = np.random.normal( loc = 0.0, scale = 1.0, size = [ num_batch, num_noise ] )\n",
    "            z = tlx.ops.convert_to_tensor( z )\n",
    "            d_loss = train_Dis( batch, z )\n",
    "            g_loss = train_Gen( batch, z )\n",
    "            \n",
    "        Gen.save_weights( '../data/Gen.npz', format = 'npz' )\n",
    "        Dis.save_weights( '../data/Dis.npz', format = 'npz' )\n",
    "        \n",
    "        Gen.set_eval()\n",
    "        result = Gen( z )\n",
    "        Gen.set_train()\n",
    "        save_images( \n",
    "            images = tlx.convert_to_numpy( result ),\n",
    "            size = [ num_tiles, num_tiles ],\n",
    "            image_path = f'../data/train_{epoch}.png'\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e0a684cfe2638f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
