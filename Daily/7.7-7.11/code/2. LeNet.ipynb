{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:20:30.511599400Z",
     "start_time": "2024-07-10T07:20:30.472369600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. 定义一个类继承于父类nn.Module\n",
    "2. 两个函数\n",
    "    1) \\_\\_init\\_\\_( self, in_channels(特征矩阵深度)， out_channels（卷积核个数）, kernel_size(卷积核大小）， stride = 1, padding = 0, ...\n",
    "        Conv2d( 深度， 卷积核个数， 卷积核大小（边长） ）\n",
    "        最大下采样：MaxPoolNd( 卷积核大小, stride=不定义即为卷积核大小, ...\n",
    "        Linear 展平\n",
    "   2) forward\n",
    "        结合卷积结果和激活函数\n",
    "        view函数：展平成一维"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be568cfa8719d47e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super( LeNet, self ).__init__()      #解决继承过程中的问题\n",
    "        self.conv1 = nn.Conv2d( 3, 16, 5 )\n",
    "        self.pool1 = nn.MaxPool2d( 2, 2 )   # 改变高和宽，不影响深度 eg. 16, 28, 28 -> 16, 14, 14\n",
    "        self.conv2 = nn.Conv2d( 16, 32, 5 ) # 第2个conv输出的卷积核深度为16，到第2个卷积核深度\n",
    "        self.pool2 = nn.MaxPool2d( 2, 2 )\n",
    "        self.fc1 = nn.Linear( 32*5*5, 120 )\n",
    "        self.fc2 = nn.Linear( 120, 84 )\n",
    "        self.fc3 = nn.Linear( 84, 10 )\n",
    "    def forward(self, x):\n",
    "        x = F.relu( self.conv1( x ) )       # in: 3, 32, 32  out: 16, 28, 28\n",
    "        x = self.pool1( x )                 # out: 16, 14, 14\n",
    "        x = F.relu( self.conv2( x ) )       # out: 32, 10, 10\n",
    "        x = self.pool2( x )                 # out: 32, 5, 5\n",
    "        x = x.view( -1, 32*5*5 )            # out: 32*5*5\n",
    "        x = F.relu( self.fc1( x ) )         # out: 120\n",
    "        x = F.relu( self.fc2( x ) )         # out: 84\n",
    "        x = self.fc3( x )                   # out: 10\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:20:30.524409800Z",
     "start_time": "2024-07-10T07:20:30.518289Z"
    }
   },
   "id": "eadf68077362b673",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "488f8a99d3fc8364"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nimport torch\\nin1 = torch.rand( [32, 3, 32, 32] )\\nmodel = LeNet()\\nprint( model )\\nout1 = model( in1 )\\n'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "in1 = torch.rand( [32, 3, 32, 32] )\n",
    "model = LeNet()\n",
    "print( model )\n",
    "out1 = model( in1 )\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:20:30.550625100Z",
     "start_time": "2024-07-10T07:20:30.528326900Z"
    }
   },
   "id": "174c41a5bf6d892",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "**训练集**\n",
    "transform -> 预处理\n",
    "ToTensor：Numpy/Img -> tensor\n",
    "          高度\\*宽度\\*深度 -> 0\\*0\\*1\n",
    "datasets：自带数据集，root-存储位置"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be34a5347fb4078e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10( root = './data', train = True, download = True, transform = transform )\n",
    "trainloader = DataLoader( trainset, batch_size = 64, shuffle = True, num_workers =0 )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:20:32.330712300Z",
     "start_time": "2024-07-10T07:20:30.537629300Z"
    }
   },
   "id": "97956fff24bc4b51",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "102b62ea136b113a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10( root = './data', train = False, download = False, transform = transform )\n",
    "testloader = DataLoader( testset, batch_size = 5000, shuffle = False, num_workers =0 )\n",
    "\n",
    "test_data_iter = iter( testloader )\n",
    "test_images, test_labels = next( test_data_iter )\n",
    "\n",
    "classes = ( 'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck' )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:20:33.279351600Z",
     "start_time": "2024-07-10T07:20:32.332715700Z"
    }
   },
   "id": "c10d1ae68fec597e",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d244afcfb733edc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\ndef imshow(img):\\n    img = img / 2 * 0.5                                             # 还原transform对数据的预处理\\n    npimg = img.numpy()                                             # 转化成numpy格式\\n    plt.imshow( np.transpose( npimg, ( 1, 2, 0 ) ) )                # 高度，宽度，深度\\n    plt.show\\n    \\n    \\nprint( ' '.join( '%s' % classes[ test_labels[j] ] for j in range( 4 ) ) )\\nimshow( torchvision.utils.make_grid( test_images ) )\\n\""
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def imshow(img):\n",
    "    img = img / 2 * 0.5                                             # 还原transform对数据的预处理\n",
    "    npimg = img.numpy()                                             # 转化成numpy格式\n",
    "    plt.imshow( np.transpose( npimg, ( 1, 2, 0 ) ) )                # 高度，宽度，深度\n",
    "    plt.show\n",
    "    \n",
    "    \n",
    "print( ' '.join( '%s' % classes[ test_labels[j] ] for j in range( 4 ) ) )\n",
    "imshow( torchvision.utils.make_grid( test_images ) )\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:20:33.287409Z",
     "start_time": "2024-07-10T07:20:33.281661900Z"
    }
   },
   "id": "cf3379d74d0e66a6",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss:1.658 accuracy:0.475\n",
      "[2,   500] loss:1.260 accuracy:0.558\n",
      "[3,   500] loss:1.076 accuracy:0.632\n",
      "[4,   500] loss:0.970 accuracy:0.649\n",
      "[5,   500] loss:0.882 accuracy:0.670\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "loss_f = nn.CrossEntropyLoss()                                      # 损失函数\n",
    "optimizer = optim.Adam( net.parameters(), lr = 0.001 )              # lr -> learning rate\n",
    "\n",
    "# 迭代训练集\n",
    "for ep in range( 5 ):\n",
    "    running_loss = 0.0\n",
    "    for step, data in enumerate( trainloader, start = 0 ):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()                                       # 清空历史梯度\n",
    "        outputs = net( inputs )\n",
    "        loss = loss_f( outputs, labels )\n",
    "        loss.backward()                                             # 反向传播\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if step % 500 == 499:                                       # 每500步打印\n",
    "            with torch.no_grad():                                   # 测试过程中不计算每个节点的误差损失梯度\n",
    "                outputs = net( test_images )\n",
    "                predict_y = torch.max( outputs.data, dim = 1 )[1]   # 记录index\n",
    "                accuracy = torch.eq( predict_y, test_labels ).sum().item() / test_labels.size(0)\n",
    "                print( '[%d, %5d] loss:%.3f accuracy:%.3f' % ( ep + 1, step + 1, running_loss / 500, accuracy ) )\n",
    "                running_loss = 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:21:38.086068700Z",
     "start_time": "2024-07-10T07:20:33.288409600Z"
    }
   },
   "id": "52b6fb166f9867d4",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "save_path = './path/Lenet.pth'\n",
    "torch.save(net.state_dict(), save_path)\n",
    "print( 'finished')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:21:38.098379300Z",
     "start_time": "2024-07-10T07:21:38.087070200Z"
    }
   },
   "id": "1e7e8581915f1171",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "预测"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b785be1105feb3d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EC319\\AppData\\Local\\Temp\\ipykernel_15660\\161287143.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print( classes[int(predict)] )\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize( ( 32, 32 ) ), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "net.load_state_dict(torch.load('./path/Lenet.pth'))\n",
    "\n",
    "im = Image.open('./data/test2.jpg')\n",
    "im = transform(im)                                      # 高度，宽度，深度\n",
    "im = torch.unsqueeze( im, dim = 0 )                     # 增加新的维度：batch，高度，宽度，深度\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = net( im )\n",
    "    predict = torch.max( outputs, dim = 1 )[1].numpy()  # 只取index\n",
    "print( classes[int(predict)] )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:21:38.191627800Z",
     "start_time": "2024-07-10T07:21:38.102386300Z"
    }
   },
   "id": "8513ac82cf1cc8f9",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
